{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb81755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logit, expit\n",
    "from scipy.stats import bernoulli\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from modeltools import mcmc_diagnostics\n",
    "from downcast import downcast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/unit_level_ratings.csv\",index_col = 0)\n",
    "raw_data = raw_data.sort_values(by=[\"corpus\", \"model\", \"topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating identifier for each corpus, model, and topic\n",
    "# Identifier is unique for topic \n",
    "corpus_ids = (raw_data.groupby([\"corpus\"], as_index=False)\n",
    "    .agg({\"intrusion\":\"count\"})\n",
    "    .drop(columns=\"intrusion\"))\n",
    "corpus_ids[\"corpus_id\"] = corpus_ids.index\n",
    "\n",
    "model_ids = (raw_data.groupby([\"model\"], as_index=False)\n",
    "    .agg({\"intrusion\":\"count\"})\n",
    "    .drop(columns=\"intrusion\"))\n",
    "model_ids[\"model_id\"] = model_ids.index\n",
    "\n",
    "cordal_ids = (raw_data.groupby([\"corpus\", \"model\"], as_index=False)\n",
    "    .agg({\"intrusion\":\"count\"})\n",
    "    .drop(columns=\"intrusion\"))\n",
    "cordal_ids[\"cordal_id\"] = cordal_ids.index \n",
    "\n",
    "topic_ids = (raw_data.groupby([\"corpus\", \"model\", \"topic\"], as_index=False)\n",
    "    .agg({\"intrusion\":\"count\"})\n",
    "    .drop(columns=\"intrusion\"))\n",
    "topic_ids[\"topic_id\"] = topic_ids.index \n",
    "\n",
    "rater_ids = (raw_data.groupby([\"corpus\", \"rater\"], as_index=False)\n",
    "    .agg({\"intrusion\":\"count\"})\n",
    "    .drop(columns=\"intrusion\"))\n",
    "rater_ids[\"rater_id\"] = rater_ids.index \n",
    "\n",
    "\n",
    "d1 = pd.merge(raw_data, corpus_ids, on=[\"corpus\"], how=\"left\")\n",
    "d2 = pd.merge(d1, model_ids, on=[\"model\"], how=\"left\")\n",
    "d3 = pd.merge(d2, cordal_ids, on=[\"corpus\",\"model\"], how=\"left\")\n",
    "d4 = pd.merge(d3, rater_ids, on=[\"corpus\", \"rater\"], how=\"left\")\n",
    "data = pd.merge(d4, topic_ids, on=[\"corpus\", \"model\", \"topic\"], how=\"left\")\n",
    "data = data[[\"corpus_id\", \"model_id\", \"cordal_id\", \"topic_id\", \"rater_id\", \"intrusion\", \"confidence\"]]\n",
    "data, na_s = downcast_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up numpy arrays for pymc\n",
    "corpora_array = np.array(data[\"corpus_id\"])\n",
    "n_corpora = data[\"corpus_id\"].nunique()\n",
    "\n",
    "models_array = np.array(data[\"model_id\"])\n",
    "n_models = data[\"model_id\"].nunique()\n",
    "\n",
    "cordals_array = np.array(data[\"cordal_id\"])\n",
    "n_cordals = data[\"cordal_id\"].nunique()\n",
    "\n",
    "topics_array = np.array(data[\"topic_id\"])\n",
    "n_topics = data[\"topic_id\"].nunique()\n",
    "\n",
    "raters_array = np.array(data[\"rater_id\"])\n",
    "n_raters = data[\"rater_id\"].nunique()\n",
    "\n",
    "scores_array = np.array(data[\"intrusion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9181a",
   "metadata": {},
   "source": [
    "## Finding optimal prior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad36a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_topic_corpora_model = {\"model\":pm.Model()}\n",
    "prior_mean = logit(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86284b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"divergence_schema.csv\", index_col=0).to_csv(\"divergence_log.csv\")\n",
    "pd.read_csv(\"summary_stat_schema.csv\", index_col=0).to_csv(\"summary_stat_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d58724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic and cordal model\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    cm_scale_param = trial.suggest_float(\"cm_scale_param\", 1e-2, 1, log=True)\n",
    "    a_scale_param = trial.suggest_float(\"a_scale_param\", 1e-2, 1, log=True)\n",
    "\n",
    "    glm_topic_corpora_model[\"model\"] = pm.Model()\n",
    "    with glm_topic_corpora_model[\"model\"]:\n",
    "        # Hyperparameter priors\n",
    "        sigma_c = pm.Exponential(\"sigma_c\", lam=2)\n",
    "        zc = pm.Normal(\"zc\",mu=prior_mean, sigma=cm_scale_param, shape=n_corpora)\n",
    "        sigma_m = pm.Exponential(\"sigma_m\", lam=2)\n",
    "        zm = pm.Normal(\"zm\",mu=0, sigma=cm_scale_param, shape=n_models)\n",
    "        sigma_a = pm.Exponential(\"sigma_a\", lam=2)\n",
    "        za = pm.Normal(\"za\",mu=0, sigma=a_scale_param, shape=n_topics)\n",
    "\n",
    "        p = pm.math.invlogit(\n",
    "            za[topics_array]*sigma_a+\n",
    "            zc[corpora_array]*sigma_c+\n",
    "            zm[models_array]*sigma_m)\n",
    "        s = pm.Bernoulli(\"s\", p=p, observed=scores_array)\n",
    "\n",
    "        glm_topic_corpora_model[\"trace\"]=pm.sample(cores=2)\n",
    "\n",
    "    # Recording divergences\n",
    "    diverge = pd.DataFrame(glm_topic_corpora_model[\"trace\"].sample_stats[\"diverging\"]).sum(axis=\"columns\")\n",
    "    total_divergences = diverge.sum()\n",
    "    diverge = pd.DataFrame(diverge).T.rename(columns={0:\"0\", 1:\"1\"})\n",
    "    diverge[\"c_sigma\"] = cm_scale_param\n",
    "    diverge[\"a_sigma\"] = a_scale_param\n",
    "    all_divergences = pd.read_csv(\"divergence_log.csv\", index_col=0)\n",
    "    all_divergences = pd.concat([all_divergences, diverge], axis=\"rows\")\n",
    "    all_divergences.to_csv(\"divergence_log.csv\")\n",
    "\n",
    "    # Recording summary_stats\n",
    "    summary_stat = az.summary(glm_topic_corpora_model[\"trace\"], round_to=4).reset_index()\n",
    "    summary_stat[\"param\"] = summary_stat[\"index\"].str.split(\"[\").str[0]\n",
    "    summary_stat[\"param_num\"] = summary_stat[\"index\"].str.split(\"[\").str[1].str[:-1]\n",
    "    summary_stat[\"param\"] = summary_stat[\"param\"].astype(\"category\")\n",
    "    summary_stat[\"param_num\"] = summary_stat[\"param_num\"].astype(\"category\")\n",
    "    summary_stat = summary_stat[[\"param\", \"param_num\"]+list(summary_stat.columns[1:-2])]\n",
    "    summary_stat[\"c_sigma\"] = cm_scale_param\n",
    "    summary_stat[\"a_sigma\"] = a_scale_param\n",
    "    all_stats = pd.read_csv(\"summary_stat_log.csv\", index_col=0)\n",
    "    all_stats = pd.concat([all_stats, summary_stat], axis=\"rows\")\n",
    "    all_stats.to_csv(\"summary_stat_log.csv\")\n",
    "    return total_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c24396",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
